{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam13juna/Documents/virtual_envs/mlo/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated: max_holes (datamodule.py, line 76)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/Documents/virtual_envs/mlo/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3378\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn [1], line 30\u001b[0;36m\n\u001b[0;31m    from S9.datamodule import CIFARDataModule\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Documents/learn/tsai/eva_8/S9/datamodule.py:76\u001b[0;36m\u001b[0m\n\u001b[0;31m    A.CoarseDropout(max_holes=1, max_height=8, max_width=8, min_holes=1, max_holes=1,  min_height=8, min_width=8, fill_value=cifar_mean, mask_fill_value=None),\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: max_holes\n"
     ]
    }
   ],
   "source": [
    "import pyrootutils\n",
    "import sys\n",
    "\n",
    "root = pyrootutils.setup_root(\n",
    "    search_from=sys.path[0],\n",
    "    pythonpath=True,\n",
    "    cwd=True,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from core_utils import main\n",
    "from core_utils.utils import data_handling, train, test, gradcam, helpers, augmentation\n",
    "from core_utils.models import resnet, s8_custom_resnet\n",
    "from pprint import pprint\n",
    "# from torch_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "import timm\n",
    "import urllib\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from S9.datamodule import CIFARDataModule\n",
    "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Add image S9/image/README/1677323174964.png -->\n",
    "\n",
    "![Instructions for S9](image/README/1677323174964.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create train_loader from torchvision datasets cifar10\n",
    "batch_size=32\n",
    "cifar_dm = CIFARDataModule(batch_size=batch_size)\n",
    "cifar_dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract train_loader from cifar_dm\n",
    "train_loader = cifar_dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a batch of images and labels from train_loader\n",
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_out = (n_in - k + 2*p)/s + 1\n",
    "# j_out = j_in * s\n",
    "# r_out = r_in + (k - 1) * j_in\n",
    "# j_in = j_out_previous, initially 1\n",
    "\n",
    "# Output size = (Input size + 2 * padding - dilation * (kernel size - 1) - 1) / stride + 1\n",
    "\n",
    "# n_out = (n_in + 2* p - d*(k-1) - 1)/s + 1\n",
    "\n",
    "# so if d == 1 then n_out = (n_in + 2*p - k)/s + 1\n",
    "# so if d == 2 then n_out = (n_in + 2*p - 2k + 1)/s + 1\n",
    "# so if d == 3 then n_out = (n_in + 2*p - 3k + 2)/s + 1\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class PrintShape(nn.Module):\n",
    "    def __init__(self, text=None):\n",
    "        super(PrintShape, self).__init__()\n",
    "        self.text = text\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"For the: \", self.text, \" the shape is: \", x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class ULTIMUS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ULTIMUS, self).__init__()\n",
    "        self.key  = nn.Linear(in_features=48, out_features=8, bias=False)\n",
    "        self.query = nn.Linear(in_features=48, out_features=8, bias=False)\n",
    "        self.value = nn.Linear(in_features=48, out_features=8, bias=False)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.out = nn.Linear(in_features=8, out_features=48, bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "       \n",
    "        key = self.key(x)\n",
    "        query = self.query(x)\n",
    "        value = self.value(x)\n",
    "\n",
    "        softmax_output = self.softmax(torch.matmul(query.T, key)/torch.sqrt(torch.tensor(8.0)))\n",
    "\n",
    "        pre_output = torch.matmul(value, softmax_output)\n",
    "\n",
    "        output = self.out(pre_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class Att_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Att_Model, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            # Here n_in=32, n_out=32, k = 3, p = 1, s = 1, d = 1, j_in=1, r_out = 3\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # Here n_in=32, n_out=32, k = 3, p = 1, s = 1, d = 1, j_in=1, r_out = 5\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=48, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU()\n",
    "            # Here n_in=32, n_out=32, k = 3, p = 1, s = 1, d = 1, j_in=1, r_out = 7\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.ultimus_1 = ULTIMUS()\n",
    "        self.ultimus_2 = ULTIMUS()\n",
    "        self.ultimus_3 = ULTIMUS()\n",
    "        self.ultimus_4 = ULTIMUS()\n",
    "\n",
    "        \n",
    "\n",
    "        self.final_layer = nn.Linear(in_features=48, out_features=10, bias=False)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv_layer(x)\n",
    "\n",
    "        average_pooled = self.avg_pool(x)\n",
    "\n",
    "        # squash the output of the average pool layer\n",
    "        average_pooled = average_pooled.view(average_pooled.size(0), -1)\n",
    "        \n",
    "        ultimus_1_output = self.ultimus_1(average_pooled)\n",
    "\n",
    "        ultimus_2_output = self.ultimus_2(ultimus_1_output)\n",
    "\n",
    "        ultimus_3_output = self.ultimus_3(ultimus_2_output)\n",
    "\n",
    "        ultimus_4_output = self.ultimus_4(ultimus_3_output)\n",
    "\n",
    "        final_output = self.final_layer(ultimus_4_output)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# print model summary using torchsummary\n",
    "# eva = Att_Model()\n",
    "# eva = eva.to(\"cuda\")\n",
    "# from torchsummary import summary\n",
    "# summary(eva, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitResnet(LightningModule):\n",
    "    def __init__(self, lr=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.model = Att_Model() \n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        # loss = F.nll_loss(logits, y)\n",
    "        loss = self.ce(logits, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        # loss = F.nll_loss(logits, y)\n",
    "        loss = self.ce(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
    "            self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr,  weight_decay=5e-4)\n",
    "        \n",
    "        # Use OnecycleLR\n",
    "        # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.005, pct_start=0.2, div_factor=10, final_div_factor=10, steps_per_epoch=len(cifar_dm.train_dataloader()), epochs=24)\n",
    "\n",
    "        # return [optimizer], [scheduler]\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type      | Params\n",
      "---------------------------------------\n",
      "0 | model    | Att_Model | 25.7 K\n",
      "1 | accuracy | Accuracy  | 0     \n",
      "---------------------------------------\n",
      "25.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.7 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam13juna/Documents/virtual_envs/mlo/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/shivam13juna/Documents/virtual_envs/mlo/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1564/1564 [00:23<00:00, 66.54it/s, loss=2.3, v_num=24, val_loss=2.300, val_acc=0.101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1564/1564 [00:23<00:00, 66.51it/s, loss=2.3, v_num=24, val_loss=2.300, val_acc=0.101]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/shivam13juna/Documents/virtual_envs/mlo/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 313/313 [00:02<00:00, 136.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000000149011612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.30259108543396      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000000149011612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.30259108543396     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 2.30259108543396, 'test_acc': 0.10000000149011612}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LitResnet(lr=0.005)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None, \n",
    ")\n",
    "\n",
    "trainer.fit(model, cifar_dm)\n",
    "trainer.test(model, datamodule=cifar_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('mlo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "166496c61138a32d9d6f298a779727d389a647554eedcb433b9a55285638df27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
