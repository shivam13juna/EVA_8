# Session 9 Assignment - HandsOn & ResNets an Higher Receptive Fields

## EVA8 Core Utils

As required, an additional repo was created with models, utils and main files in the following location: [EVA 8 Utils](https://github.com/shivam13juna/eva8_utils.git)


## Link to custom ResNet Model

Here's the link to the [Custom Attention Network](https://github.com/shivam13juna/eva8_utils/blob/master/models/s8_custom_resnet.py)


I couldn't get above 18%
## Training Logs
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 32, 32]             432
       BatchNorm2d-2           [-1, 16, 32, 32]              32
              ReLU-3           [-1, 16, 32, 32]               0
            Conv2d-4           [-1, 32, 32, 32]           4,608
       BatchNorm2d-5           [-1, 32, 32, 32]              64
              ReLU-6           [-1, 32, 32, 32]               0
            Conv2d-7           [-1, 48, 32, 32]          13,824
       BatchNorm2d-8           [-1, 48, 32, 32]              96
              ReLU-9           [-1, 48, 32, 32]               0
AdaptiveAvgPool2d-10             [-1, 48, 1, 1]               0
           Linear-11                    [-1, 8]             384
           Linear-12                    [-1, 8]             384
           Linear-13                    [-1, 8]             384
          Softmax-14                    [-1, 8]               0
           Linear-15                   [-1, 48]             384
          ULTIMUS-16                   [-1, 48]               0
           Linear-17                    [-1, 8]             384
           Linear-18                    [-1, 8]             384
           Linear-19                    [-1, 8]             384
          Softmax-20                    [-1, 8]               0
           Linear-21                   [-1, 48]             384
          ULTIMUS-22                   [-1, 48]               0
           Linear-23                    [-1, 8]             384
           Linear-24                    [-1, 8]             384
           Linear-25                    [-1, 8]             384
          Softmax-26                    [-1, 8]               0
           Linear-27                   [-1, 48]             384
          ULTIMUS-28                   [-1, 48]               0
           Linear-29                    [-1, 8]             384
           Linear-30                    [-1, 8]             384
           Linear-31                    [-1, 8]             384
          Softmax-32                    [-1, 8]               0
           Linear-33                   [-1, 48]             384
          ULTIMUS-34                   [-1, 48]               0
           Linear-35                   [-1, 10]             480
================================================================
Total params: 25,680
Trainable params: 25,680
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 2.25
Params size (MB): 0.10
Estimated Total Size (MB): 2.36
----------------------------------------------------------------
EPOCH: 1
Loss=1.9261754751205444 Batch_id=97 LR=0.00576 Accuracy=17.18: 100%|█| 98/98 [00

Test set: Average loss: 0.0040, Accuracy: 1848/10000 (18.48%)

EPOCH: 2
Loss=1.8687824010849 Batch_id=97 LR=0.00952 Accuracy=18.68: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:12<00:00,  7.55it/s]

Test set: Average loss: 0.0038, Accuracy: 1755/10000 (17.55%)

EPOCH: 3
Loss=1.883676290512085 Batch_id=97 LR=0.01327 Accuracy=18.65: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.47it/s]

Test set: Average loss: 0.0037, Accuracy: 1873/10000 (18.73%)

EPOCH: 4
Loss=2.8053667545318604 Batch_id=97 LR=0.01703 Accuracy=17.52: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.22it/s]

Test set: Average loss: 0.0072, Accuracy: 836/10000 (8.36%)

EPOCH: 5
Loss=2.3040177822113037 Batch_id=97 LR=0.01978 Accuracy=11.22: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.32it/s]

Test set: Average loss: 0.0046, Accuracy: 1213/10000 (12.13%)

EPOCH: 6
Loss=2.288123846054077 Batch_id=97 LR=0.01874 Accuracy=11.93: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.10it/s]

Test set: Average loss: 0.0046, Accuracy: 1216/10000 (12.16%)

EPOCH: 7
Loss=2.279232978820801 Batch_id=97 LR=0.01770 Accuracy=12.01: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.27it/s]

Test set: Average loss: 0.0046, Accuracy: 1222/10000 (12.22%)

EPOCH: 8
Loss=2.2892038822174072 Batch_id=97 LR=0.01666 Accuracy=12.14: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.30it/s]

Test set: Average loss: 0.0046, Accuracy: 1255/10000 (12.55%)

EPOCH: 9
Loss=2.2847158908843994 Batch_id=97 LR=0.01562 Accuracy=12.86: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.35it/s]

Test set: Average loss: 0.0046, Accuracy: 1352/10000 (13.52%)

EPOCH: 10
Loss=2.27340030670166 Batch_id=97 LR=0.01458 Accuracy=13.21: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.24it/s]

Test set: Average loss: 0.0046, Accuracy: 1367/10000 (13.67%)

EPOCH: 11
Loss=2.2691032886505127 Batch_id=97 LR=0.01354 Accuracy=13.18: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.48it/s]

Test set: Average loss: 0.0046, Accuracy: 1342/10000 (13.42%)

EPOCH: 12
Loss=2.2798781394958496 Batch_id=97 LR=0.01250 Accuracy=12.91: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.30it/s]

Test set: Average loss: 0.0046, Accuracy: 1354/10000 (13.54%)

EPOCH: 13
Loss=2.2902867794036865 Batch_id=97 LR=0.01146 Accuracy=13.10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.19it/s]

Test set: Average loss: 0.0046, Accuracy: 1304/10000 (13.04%)

EPOCH: 14
Loss=2.2735180854797363 Batch_id=97 LR=0.01043 Accuracy=12.89: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.20it/s]

Test set: Average loss: 0.0045, Accuracy: 1316/10000 (13.16%)

EPOCH: 15
Loss=2.277397394180298 Batch_id=97 LR=0.00939 Accuracy=12.44: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.20it/s]

Test set: Average loss: 0.0045, Accuracy: 1200/10000 (12.00%)

EPOCH: 16
Loss=2.2737650871276855 Batch_id=97 LR=0.00835 Accuracy=11.52: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.23it/s]

Test set: Average loss: 0.0045, Accuracy: 1097/10000 (10.97%)

EPOCH: 17
Loss=2.260732650756836 Batch_id=97 LR=0.00731 Accuracy=10.81: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:14<00:00,  6.98it/s]

Test set: Average loss: 0.0045, Accuracy: 1070/10000 (10.70%)

EPOCH: 18
Loss=2.2304205894470215 Batch_id=97 LR=0.00627 Accuracy=11.42: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:14<00:00,  6.94it/s]

Test set: Average loss: 0.0045, Accuracy: 1449/10000 (14.49%)

EPOCH: 19
Loss=2.104253053665161 Batch_id=97 LR=0.00523 Accuracy=16.48: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.03it/s]

Test set: Average loss: 0.0042, Accuracy: 1786/10000 (17.86%)

EPOCH: 20
Loss=2.063572406768799 Batch_id=97 LR=0.00419 Accuracy=17.88: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:13<00:00,  7.11it/s]

Test set: Average loss: 0.0041, Accuracy: 1813/10000 (18.13%)

EPOCH: 21
Loss=2.038076162338257 Batch_id=97 LR=0.00315 Accuracy=18.06: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:14<00:00,  6.76it/s]

Test set: Average loss: 0.0041, Accuracy: 1806/10000 (18.06%)

EPOCH: 22
Loss=2.056413173675537 Batch_id=97 LR=0.00211 Accuracy=18.14: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:17<00:00,  5.57it/s]

Test set: Average loss: 0.0040, Accuracy: 1843/10000 (18.43%)

EPOCH: 23
Loss=2.100748062133789 Batch_id=97 LR=0.00107 Accuracy=18.33: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:20<00:00,  4.83it/s]

Test set: Average loss: 0.0040, Accuracy: 1857/10000 (18.57%)

EPOCH: 24
Loss=2.055715322494507 Batch_id=97 LR=0.00003 Accuracy=18.49: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:18<00:00,  5.37it/s]

Test set: Average loss: 0.0039, Accuracy: 1850/10000 (18.50%)