{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "de76b3ab",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-28T08:16:23.654358Z",
          "iopub.status.busy": "2022-04-28T08:16:23.653823Z",
          "iopub.status.idle": "2022-04-28T08:16:25.949844Z",
          "shell.execute_reply": "2022-04-28T08:16:25.950283Z"
        },
        "id": "de76b3ab",
        "outputId": "9fff2490-9646-42bc-88d6-0aadbac62df8",
        "papermill": {
          "duration": 2.333018,
          "end_time": "2022-04-28T08:16:25.950458",
          "exception": false,
          "start_time": "2022-04-28T08:16:23.617440",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shivam13juna/Documents/virtual_envs/cap/lib/python3.10/site-packages/pl_bolts/callbacks/data_monitor.py:20: UnderReviewWarning: The feature warn_missing_pkg is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  warn_missing_pkg(\"wandb\")\n",
            "/home/shivam13juna/Documents/virtual_envs/cap/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:35: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/home/shivam13juna/Documents/virtual_envs/cap/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:93: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/home/shivam13juna/Documents/virtual_envs/cap/lib/python3.10/site-packages/pl_bolts/losses/self_supervised_learning.py:234: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/home/shivam13juna/Documents/virtual_envs/cap/lib/python3.10/site-packages/pl_bolts/datamodules/experience_source.py:18: UnderReviewWarning: The feature warn_missing_pkg is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  warn_missing_pkg(\"gym\")\n",
            "Global seed set to 7\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from pl_bolts.datamodules import CIFAR10DataModule\n",
        "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.optim.swa_utils import AveragedModel, update_bn\n",
        "seed_everything(7)\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
        "BATCH_SIZE = 256 if torch.cuda.is_available() else 64"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34f13886",
      "metadata": {
        "id": "34f13886",
        "papermill": {
          "duration": 0.066591,
          "end_time": "2022-04-28T08:16:26.050000",
          "exception": false,
          "start_time": "2022-04-28T08:16:25.983409",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### CIFAR10 Data Module\n",
        "\n",
        "Import the existing data module from `bolts` and modify the train and test transforms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f6a1c0e6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-28T08:16:26.125632Z",
          "iopub.status.busy": "2022-04-28T08:16:26.125100Z",
          "iopub.status.idle": "2022-04-28T08:16:26.128348Z",
          "shell.execute_reply": "2022-04-28T08:16:26.127879Z"
        },
        "id": "f6a1c0e6",
        "outputId": "099e498b-b24b-41ad-8b10-c67fca5a35ff",
        "papermill": {
          "duration": 0.04236,
          "end_time": "2022-04-28T08:16:26.128471",
          "exception": false,
          "start_time": "2022-04-28T08:16:26.086111",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "train_transforms = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.RandomCrop(32, padding=4),\n",
        "        torchvision.transforms.RandomHorizontalFlip(),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        cifar10_normalization(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_transforms = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        cifar10_normalization(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "cifar10_dm = CIFAR10DataModule(\n",
        "    data_dir=PATH_DATASETS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    train_transforms=train_transforms,\n",
        "    test_transforms=test_transforms,\n",
        "    val_transforms=test_transforms,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebc0eaa",
      "metadata": {
        "id": "3ebc0eaa",
        "lines_to_next_cell": 2,
        "papermill": {
          "duration": 0.035124,
          "end_time": "2022-04-28T08:16:26.195622",
          "exception": false,
          "start_time": "2022-04-28T08:16:26.160498",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Model Architecture \n",
        "Modify the pre-existing Resnet architecture from TorchVision. The pre-existing architecture is based on ImageNet\n",
        "images (224x224) as input. So we need to modify it for CIFAR10 images (32x32)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "96ff098b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-28T08:16:26.265523Z",
          "iopub.status.busy": "2022-04-28T08:16:26.265004Z",
          "iopub.status.idle": "2022-04-28T08:16:26.267046Z",
          "shell.execute_reply": "2022-04-28T08:16:26.267460Z"
        },
        "id": "96ff098b",
        "lines_to_next_cell": 2,
        "papermill": {
          "duration": 0.039053,
          "end_time": "2022-04-28T08:16:26.267599",
          "exception": false,
          "start_time": "2022-04-28T08:16:26.228546",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the:  conv1_block_input  the shape is:  torch.Size([2, 3, 32, 32])\n",
            "For the:  conv1_block_c1_output  the shape is:  torch.Size([2, 32, 32, 32])\n",
            "For the:  conv1_block_c2_output  the shape is:  torch.Size([2, 32, 32, 32])\n",
            "For the:  conv1_block_c3_output  the shape is:  torch.Size([2, 64, 32, 32])\n",
            "For the:  conv2_block_input  the shape is:  torch.Size([2, 64, 32, 32])\n",
            "For the:  conv2_block_c1_output  the shape is:  torch.Size([2, 64, 32, 32])\n",
            "For the:  conv2_block_c2_output  the shape is:  torch.Size([2, 128, 28, 28])\n",
            "For the:  conv2_block_c3_output  the shape is:  torch.Size([2, 128, 24, 24])\n",
            "For the:  conv3_block_input  the shape is:  torch.Size([2, 128, 24, 24])\n",
            "For the:  conv3_block_c1_output  the shape is:  torch.Size([2, 128, 20, 20])\n",
            "For the:  conv3_block_c2_output  the shape is:  torch.Size([2, 128, 14, 14])\n",
            "For the:  conv3_block_c3_output  the shape is:  torch.Size([2, 128, 8, 8])\n",
            "For the:  conv3_block_c4_output  the shape is:  torch.Size([2, 128, 2, 2])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "        PrintShape-1            [-1, 3, 32, 32]               0\n",
            "            Conv2d-2           [-1, 32, 32, 32]             864\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "       BatchNorm2d-4           [-1, 32, 32, 32]              64\n",
            "           Dropout-5           [-1, 32, 32, 32]               0\n",
            "        PrintShape-6           [-1, 32, 32, 32]               0\n",
            "            Conv2d-7           [-1, 32, 32, 32]           9,216\n",
            "              ReLU-8           [-1, 32, 32, 32]               0\n",
            "       BatchNorm2d-9           [-1, 32, 32, 32]              64\n",
            "          Dropout-10           [-1, 32, 32, 32]               0\n",
            "       PrintShape-11           [-1, 32, 32, 32]               0\n",
            "           Conv2d-12           [-1, 64, 32, 32]          18,432\n",
            "             ReLU-13           [-1, 64, 32, 32]               0\n",
            "      BatchNorm2d-14           [-1, 64, 32, 32]             128\n",
            "          Dropout-15           [-1, 64, 32, 32]               0\n",
            "       PrintShape-16           [-1, 64, 32, 32]               0\n",
            "       PrintShape-17           [-1, 64, 32, 32]               0\n",
            "           Conv2d-18           [-1, 64, 32, 32]          36,864\n",
            "             ReLU-19           [-1, 64, 32, 32]               0\n",
            "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
            "          Dropout-21           [-1, 64, 32, 32]               0\n",
            "       PrintShape-22           [-1, 64, 32, 32]               0\n",
            "           Conv2d-23          [-1, 128, 28, 28]           1,152\n",
            "             ReLU-24          [-1, 128, 28, 28]               0\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "          Dropout-26          [-1, 128, 28, 28]               0\n",
            "       PrintShape-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 24, 24]           1,152\n",
            "             ReLU-29          [-1, 128, 24, 24]               0\n",
            "      BatchNorm2d-30          [-1, 128, 24, 24]             256\n",
            "          Dropout-31          [-1, 128, 24, 24]               0\n",
            "       PrintShape-32          [-1, 128, 24, 24]               0\n",
            "       PrintShape-33          [-1, 128, 24, 24]               0\n",
            "           Conv2d-34          [-1, 128, 20, 20]         147,456\n",
            "             ReLU-35          [-1, 128, 20, 20]               0\n",
            "      BatchNorm2d-36          [-1, 128, 20, 20]             256\n",
            "          Dropout-37          [-1, 128, 20, 20]               0\n",
            "       PrintShape-38          [-1, 128, 20, 20]               0\n",
            "           Conv2d-39          [-1, 128, 14, 14]         147,456\n",
            "             ReLU-40          [-1, 128, 14, 14]               0\n",
            "      BatchNorm2d-41          [-1, 128, 14, 14]             256\n",
            "          Dropout-42          [-1, 128, 14, 14]               0\n",
            "       PrintShape-43          [-1, 128, 14, 14]               0\n",
            "           Conv2d-44            [-1, 128, 8, 8]         147,456\n",
            "             ReLU-45            [-1, 128, 8, 8]               0\n",
            "      BatchNorm2d-46            [-1, 128, 8, 8]             256\n",
            "          Dropout-47            [-1, 128, 8, 8]               0\n",
            "       PrintShape-48            [-1, 128, 8, 8]               0\n",
            "           Conv2d-49            [-1, 128, 2, 2]         147,456\n",
            "             ReLU-50            [-1, 128, 2, 2]               0\n",
            "      BatchNorm2d-51            [-1, 128, 2, 2]             256\n",
            "          Dropout-52            [-1, 128, 2, 2]               0\n",
            "       PrintShape-53            [-1, 128, 2, 2]               0\n",
            "        AvgPool2d-54            [-1, 128, 1, 1]               0\n",
            "           Linear-55                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 660,714\n",
            "Trainable params: 660,714\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 18.47\n",
            "Params size (MB): 2.52\n",
            "Estimated Total Size (MB): 21.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "class PrintShape(nn.Module):\n",
        "    def __init__(self, text=None):\n",
        "        super(PrintShape, self).__init__()\n",
        "        self.text = text\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"For the: \", self.text, \" the shape is: \", x.shape)\n",
        "        return x\n",
        "\n",
        "\n",
        "class eva_s6(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(eva_s6, self).__init__()\n",
        "        \n",
        "        # n_out = (n_in - k + 2*p)/s + 1\n",
        "        # j_out = j_in * s\n",
        "        # r_out = r_in + (k - 1) * j_in\n",
        "        # j_in = j_out_previous, initially 1\n",
        "\n",
        "        # Output size = (Input size + 2 * padding - dilation * (kernel size - 1) - 1) / stride + 1\n",
        "\n",
        "        # n_out = (n_in + 2* p - d*(k-1) - 1)/s + 1\n",
        "\n",
        "        # so if d == 1 then n_out = (n_in + 2*p - k)/s + 1\n",
        "        # so if d == 2 then n_out = (n_in + 2*p - 2k + 1)/s + 1\n",
        "        # so if d == 3 then n_out = (n_in + 2*p - 3k + 2)/s + 1\n",
        "\n",
        "        self.conv1_block = nn.Sequential(\n",
        "            PrintShape(\"conv1_block_input\"),\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2, dilation=2, bias=False), \n",
        "            # n_in = 32, k = 3, p = 1, n_out = 32, j_in = 1, j_out = 1, r_out = 5; 32 x 32 x 32\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "            PrintShape(\"conv1_block_c1_output\"),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=2, dilation=2, bias=False),\n",
        "            # n_in = 32, k = 5, p = 1, n_out = 32, j_in = 1, j_out = 1, r_out =  9; 32 x 32 x 32\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "            PrintShape(\"conv1_block_c2_output\"),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2, dilation=2, bias=False),\n",
        "            # n_in = 32, k = 5, p = 1, n_out = 32, j_in = 1, j_out = 1, r_out = 13; 32 x 32 x 64\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "            PrintShape(\"conv1_block_c3_output\")\n",
        "            )\n",
        "\n",
        "\n",
        "# so if d == 2 then n_out = (n_in + 2*p - 2k + 1)/s + 1\n",
        "# 32 + 2 * 0 \n",
        "        \n",
        "        self.conv2_block = nn.Sequential(\n",
        "\n",
        "            PrintShape(\"conv2_block_input\"),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=2, dilation=2, bias=False),\n",
        "            # n_in = 32, k = 5, p = 1, n_out = 32, j_in = 1, j_out = 1, r_out = 17; 32 x 32 x 64\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "            PrintShape(\"conv2_block_c1_output\"),\n",
        "            \n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, dilation = 2, groups=64, bias=False),\n",
        "            # n_in = 32, k = 5, p = 0, n_out = 28, j_in = 1, j_out = 1, r_out = 21; 28 x 28 x 128\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "            PrintShape(\"conv2_block_c2_output\"),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, groups=128, dilation=2, bias=False),\n",
        "            # n_in = 28, k = 5, p = 0, n_out = 24, j_in = 1, j_out = 1, r_out = 25; 26 x 26 x 128\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "            PrintShape(\"conv2_block_c3_output\")\n",
        "            )\n",
        "\n",
        "# so if d == 3 then n_out = (n_in + 2*p - 3k + 2)/s + 1\n",
        "        self.conv3_block = nn.Sequential(\n",
        "\n",
        "            PrintShape(\"conv3_block_input\"),\n",
        "\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, dilation=3, bias=False),\n",
        "            # n_in = 24, k = 6, p = 0, n_out = 19, j_in = 1, j_out = 1, r_out = 30; 20 x 20 x 128\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "            PrintShape(\"conv3_block_c1_output\"),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0, dilation=3, bias=False),\n",
        "            # n_in = 18, k = 6, p = 0, n_out = 14, j_in = 1, j_out = 1, r_out = 35; 16 x 16 x 128\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "            PrintShape(\"conv3_block_c2_output\"),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0, dilation=3, bias=False),\n",
        "            # n_in = 12, k = 6, p = 0, n_out = 9, j_in = 1, j_out = 1, r_out = 40; 11 x 11 x 128\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "            PrintShape(\"conv3_block_c3_output\"),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0, dilation=3, bias=False),\n",
        "            # n_in = 6, k = 6, p = 0, n_out = 4, j_in = 1, j_out = 1, r_out = 45; 6 x 6 x 128\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "            PrintShape(\"conv3_block_c4_output\")\n",
        "            )\n",
        "\n",
        "            # Use global average pooling\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=2)\n",
        "        ) # output_size = 1\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_block(x)\n",
        "        x = self.conv2_block(x)\n",
        "        x = self.conv3_block(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 128)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "\n",
        "        \n",
        "        return x\n",
        "\n",
        "# print model summary using torchsummary\n",
        "eva = eva_s6()\n",
        "eva = eva.to(\"cuda\")\n",
        "from torchsummary import summary\n",
        "summary(eva, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ff098b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-28T08:16:26.265523Z",
          "iopub.status.busy": "2022-04-28T08:16:26.265004Z",
          "iopub.status.idle": "2022-04-28T08:16:26.267046Z",
          "shell.execute_reply": "2022-04-28T08:16:26.267460Z"
        },
        "id": "96ff098b",
        "lines_to_next_cell": 2,
        "papermill": {
          "duration": 0.039053,
          "end_time": "2022-04-28T08:16:26.267599",
          "exception": false,
          "start_time": "2022-04-28T08:16:26.228546",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after conv1:  torch.Size([2, 32, 15, 15])\n",
            "Shape after conv2:  torch.Size([2, 64, 5, 5])\n",
            "Shape after conv3:  torch.Size([2, 128, 1, 1])\n",
            "Shape after global_pool:  torch.Size([2, 128, 1, 1])\n",
            "torch.Size([2, 128, 1, 1])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 15, 15]           2,432\n",
            "            Conv2d-2             [-1, 64, 5, 5]          51,264\n",
            "            Conv2d-3            [-1, 128, 1, 1]          12,928\n",
            " AdaptiveAvgPool2d-4            [-1, 128, 1, 1]               0\n",
            "            Linear-5                   [-1, 64]           8,256\n",
            "            Linear-6                   [-1, 32]           2,080\n",
            "            Linear-7                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 77,290\n",
            "Trainable params: 77,290\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.07\n",
            "Params size (MB): 0.29\n",
            "Estimated Total Size (MB): 0.38\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "class eva_s6(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(eva_s6, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, padding=2, stride=2) # n_in = 32, k = 5, p = 0, s = 2, n_out = 14, j_in = 1, j_out = 2, r_out = 5\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2, stride=2, dilation=2) # n_in = 14, k = 5, p = 0, s = 2, n_out = 5, j_in = 2, j_out = 4, r_out = 13\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=0, stride=2, groups=16) # n_in = 5, k = 5, p = 0, s = 2, n_out = 1, j_in = 4, j_out = 8, r_out = 29\n",
        "\n",
        "        # Use global pooling\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        \n",
        "        self.inp_fc1 = 128\n",
        "        self.fc1 = nn.Linear(in_features=self.inp_fc1, out_features=64)\n",
        "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
        "        self.fc3 = nn.Linear(in_features=32, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        print(\"Shape after conv1: \", x.shape)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        print(\"Shape after conv2: \", x.shape)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        print(\"Shape after conv3: \", x.shape)\n",
        "        x = self.global_pool(x)\n",
        "        print(\"Shape after global_pool: \", x.shape)\n",
        "        # print shape of x\n",
        "        print(x.shape)\n",
        "        x = x.view(-1, self.inp_fc1)\n",
        "        # x = self.fc1(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# print model summary using torchsummary\n",
        "eva = eva_s6()\n",
        "eva = eva.to(\"cuda\")\n",
        "from torchsummary import summary\n",
        "summary(eva, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2dad8bee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-28T08:16:26.416028Z",
          "iopub.status.busy": "2022-04-28T08:16:26.415462Z",
          "iopub.status.idle": "2022-04-28T08:16:26.417317Z",
          "shell.execute_reply": "2022-04-28T08:16:26.417741Z"
        },
        "id": "2dad8bee",
        "papermill": {
          "duration": 0.045442,
          "end_time": "2022-04-28T08:16:26.417903",
          "exception": false,
          "start_time": "2022-04-28T08:16:26.372461",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class LitResnet(LightningModule):\n",
        "    def __init__(self, lr=0.05):\n",
        "        super().__init__()\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "        self.model = eva_s6() \n",
        "        self.accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        return F.log_softmax(out, dim=1)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def evaluate(self, batch, stage=None):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = self.accuracy(preds, y)\n",
        "\n",
        "        if stage:\n",
        "            self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
        "            self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self.evaluate(batch, \"val\")\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        self.evaluate(batch, \"test\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(\n",
        "            self.parameters(),\n",
        "            lr=self.hparams.lr,\n",
        "            momentum=0.9,\n",
        "            weight_decay=5e-4,\n",
        "        )\n",
        "        steps_per_epoch = 45000 // BATCH_SIZE\n",
        "        scheduler_dict = {\n",
        "            \"scheduler\": OneCycleLR(\n",
        "                optimizer,\n",
        "                0.1,\n",
        "                epochs=self.trainer.max_epochs,\n",
        "                steps_per_epoch=steps_per_epoch,\n",
        "            ),\n",
        "            \"interval\": \"step\",\n",
        "        }\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_dict}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f90deeb2",
      "metadata": {},
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "75af1ce6",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "601f7f2f19734f35b81d452928e7b664",
            "bddb7b6f7d3045b58c684d286860aca2",
            "aee2f55863634bd489ee6a93f590ab1d",
            "fc801be703164975836710a9088a3e2e",
            "2fd0ebdad1cb4cdd8078e88d634a8e94",
            "a74ca8b4deb04d9fa396875fb178433f",
            "38c3342045184d4bb2364468d1aaa8eb",
            "cf2e45e1013b4e0b9a88557a51b7df9d",
            "d9c5f5b858d2414886fe8426f02ba8bf",
            "a4383d04e64545ab994007aaef8f99cc",
            "7587f9e118824d388e41e61f266a865b",
            "7f1d10ebba4749249a34a89e2f0db2e1",
            "75fa976468574d6289b4db59e25239fe",
            "8a851d74606748a0af0eb68ee3b59252",
            "f24c21c7d7fd47d19181ce0e78cc80eb",
            "9b6873f47aa64d71a179b18e3bdd0f9b",
            "db547c77de714f0d9d8aed6238b16a52",
            "635874e03bb34832aad130a3a09dace2",
            "4eaff499e6d743c198a966b529808cf7",
            "fbde9c369f2d48c7a7d3f24c4dc302df",
            "54ca5f6ad2124679a5883a24e27fa925",
            "1257b66b89514d01bfe2be14c3f4cf4a",
            "97871fe8a2794f938e11a7a789653b8c",
            "7741b5d8cde34dc7b36c1d6cd0f771e2",
            "65f5e09b1c1a4bd2bdf265e126fe4308",
            "8fc44743902b44b8bf643cfa2d3d5567",
            "37c2f9e8f4544cb189ad9debf84344e8",
            "c872d37d34dc4e00b72a782170d7a88e",
            "0ae3d35d13ed4f25bd0b09e7154c92df",
            "630e1930b9f14b5794ccecac534541a1",
            "b6e410ec2ba14f8f86a3904e4cca9c5a",
            "53849ee2ab8f41d0814af75ee735556a",
            "42fc6f7641ea45f89ac3a52f7e0f8730",
            "8d2311d8b74f4f6f9fd32346ad7d4a42"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-04-28T08:16:26.488007Z",
          "iopub.status.busy": "2022-04-28T08:16:26.487474Z",
          "iopub.status.idle": "2022-04-28T08:21:55.895718Z",
          "shell.execute_reply": "2022-04-28T08:21:55.896255Z"
        },
        "id": "75af1ce6",
        "outputId": "b28887c5-bf78-47ac-c563-ad495db6d0e8",
        "papermill": {
          "duration": 329.445947,
          "end_time": "2022-04-28T08:21:55.896421",
          "exception": false,
          "start_time": "2022-04-28T08:16:26.450474",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type               | Params\n",
            "------------------------------------------------\n",
            "0 | model    | eva_s6             | 18.0 K\n",
            "1 | accuracy | MulticlassAccuracy | 0     \n",
            "------------------------------------------------\n",
            "18.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "18.0 K    Total params\n",
            "0.072     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0bd8b1a60e24809969279abe595edac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shivam13juna/Documents/virtual_envs/cap/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/home/shivam13juna/Documents/virtual_envs/cap/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cff3d1a53174487598a79fe5e8ee6cd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shivam13juna/Documents/virtual_envs/cap/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/home/shivam13juna/Documents/virtual_envs/cap/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82886ddfa44041e08616bfb4c47e048c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([256, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([256, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([256, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([256, 64, 1, 1])\n",
            "torch.Size([256, 64, 1, 1])\n",
            "Shape after conv1:  torch.Size([16, 16, 15, 15])\n",
            "Shape after conv2:  torch.Size([16, 32, 5, 5])\n",
            "Shape after conv3:  torch.Size([16, 64, 2, 2])\n",
            "Shape after global_pool:  torch.Size([16, 64, 1, 1])\n",
            "torch.Size([16, 64, 1, 1])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14949999749660492    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.2717247009277344     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14949999749660492   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.2717247009277344    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test_loss': 2.2717247009277344, 'test_acc': 0.14949999749660492}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LitResnet(lr=0.05)\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=30,\n",
        "    accelerator=\"auto\",\n",
        "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
        ")\n",
        "\n",
        "trainer.fit(model, cifar10_dm)\n",
        "trainer.test(model, datamodule=cifar10_dm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c6f5723",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "colab_type,colab,id,-all",
      "formats": "ipynb,py:percent",
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('cap')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 16715.805757,
      "end_time": "2022-04-28T12:54:54.351239",
      "environment_variables": {},
      "exception": null,
      "input_path": "lightning_examples/cifar10-baseline/baseline.ipynb",
      "output_path": ".notebooks/lightning_examples/cifar10-baseline.ipynb",
      "parameters": {},
      "start_time": "2022-04-28T08:16:18.545482",
      "version": "2.3.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "bc8486503dbd98e5c49c83cbe9cd940d526befdb0c9637895109bfc36b5e9544"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
